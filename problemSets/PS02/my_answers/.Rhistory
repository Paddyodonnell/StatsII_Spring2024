predicted_data %>%
arrange(mod_1_hat) %>%
mutate(rank = row_number()) %>%
ggplot(aes(rank, mod_1_hat)) +
geom_point(aes(colour = hsgrad), alpha = 0.5) +
scale_y_continuous(limits = c(0,1))
predicted_data %>%
arrange(mod_2_hat) %>%
mutate(rank = row_number()) %>%
ggplot(aes(rank, mod_2_hat)) +
geom_point(aes(colour = hsgrad), alpha = 0.5) +
scale_y_continuous(limits = c(0,1))
# McFadden's R squared
# Approach 1:
mod_1$null.deviance == mod_2$null.deviance
ll.null <- mod_1$null.deviance/-2
ll.fit_1 <- mod_1$deviance/-2
ll.fit_2 <- mod_2$deviance/-2
r.sq.mod_1 <- (ll.null-ll.fit_1)/ll.null
r.sq.mod_2 <- (ll.null-ll.fit_2)/ll.null
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
## Overview
The third homework assignment covers supervised text classification methods. Important note: some of these models are extremely computationally intensive, particularly when iterating models across parameters for optimisation (i.e. grid search). You are therefore recommended to first run the models (i.e. the code chunks containing the `train()` function) in a script and use the `saveRDS()` function to store their output. You can then use the `readRDS()` function to load your model when compiling the R markdown file. This will save you having to repeatedly run the same model. When doing so, you should add a separate code chunk for the `readRDS()` function, and you should add the argument `eval = FALSE` to the chunk options (i.e. \{r eval = FALSE\}) of the chunk which runs your model (i.e. that contains the `train()` function.)
## Supervised text classification of Yelp reviews
We begin by analyzing a sample from the Zhang, Zhao & LeCun (2015) dataset of Yelp reviews, which have been coded for sentiment polarity.  The authors of the dataset have created a `sentiment` variable where a value of 1 indicates a "negative" review (1 or 2 stars), and a 2 means a "positive" review (3 or 4 stars).
First, we read in the reviews dataset.
```{r}
data <- read.csv("yelp_data_small.csv",
stringsAsFactors=FALSE,
encoding = "utf-8")
library(quanteda)
library(quanteda.textstats)
library(quanteda.textplots)
corpus <- corpus(data,
text_field = "text")
prop.table(table(corpus$sentiment))
head(corpus)
toks <- tokens(corpus,
include_docvars = TRUE)
toks <- tokens(corpus,
include_docvars = TRUE)
toks <- toks %>%
tokens_tolower() %>%
tokens_remove(stopwords("english"), padding = TRUE) %>%
tokens_remove('[\\p{P}\\p{S}]', valuetype = 'regex', padding = TRUE)
cols <- textstat_collocations(toks,
method = "lambda",
size = 2,
min_count = 5,
smoothing = 0.5)
cols <- cols[order(-cols$count),]
toks <- tokens_compound(toks, pattern = cols[cols$z > 10,])
toks <- tokens_remove(tokens(toks), "")
toks <- tokens_remove(tokens(toks), "")
toks <- tokens(toks,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_separators = TRUE,
remove_url = TRUE)
dfm <- dfm(toks)
dfm <- dfm_trim(dfm, min_termfreq = 30)
dfm <- dfm_trim(dfm, min_termfreq = 30)
dfm <- dfm_tfidf(dfm)
library(caret)
tmpdata <- convert(dfm, to = "data.frame", docvars = NULL)
tmpdata <- tmpdata[, -1]
sentiment <- as.factor(dfm@docvars$sentiment) # extract sentiment labels from the dfm object (hint: the dfm is an S4 class object)
ldata <- as.data.frame(cbind(sentiment, tmpdata))
train_row_nums <- createDataPartition(y = ldata$sentiment, # set sentiment as the Y variable in caret
p = 0.8, # fill in the blank
list=FALSE)
Train <- ldata[train_row_nums, ]
Train <- ldata[train_row_nums, ]
Test <-  ldata[-train_row_nums, ]
library('doParallel') # for parallel processing
library('naivebayes') # naive bayes classifier
library('MLmetrics') # model performance
# 1. Set grid search for NB classifier - how will you tune your parameters?
tgrid <- expand.grid(laplace = c(0,0.5,1.0),
usekernel = c(TRUE, FALSE),
adjust=c(0.75, 1, 1.25, 1.5))
# 2. Set up 5-fold cross-validation, repeated 3 times
train_control <- trainControl(method = "repeatedcv",
number = 5,
repeats = 3,
classProbs= TRUE,
summaryFunction = multiClassSummary,
selectionFunction = "best", # select the model with the best performance metric
verboseIter = TRUE)
# 3. Set parallel processing cluster
cl <- makePSOCKcluster(5) # create number of copies of R to run in parallel and communicate over sockets
registerDoParallel(cl) # register parallel backed with foreach package
# 4. Train model
nb_train <-nb_train <- train(sentiment ~ .,
data = Train,
method = "naive_bayes",
metric = "F1",
trControl = train_control,
tuneGrid = tgrid,
allowParallel= TRUE
)
library('doParallel') # for parallel processing
library('naivebayes') # naive bayes classifier
library('MLmetrics') # model performance
# 1. Set grid search for NB classifier - how will you tune your parameters?
tgrid <- expand.grid(laplace = c(0,0.5,1.0),
usekernel = c(TRUE, FALSE),
adjust=c(0.75, 1, 1.25, 1.5))
# 2. Set up 5-fold cross-validation, repeated 3 times
train_control <- trainControl(method = "repeatedcv",
number = 5,
repeats = 3,
classProbs= TRUE,
summaryFunction = multiClassSummary,
selectionFunction = "best", # select the model with the best performance metric
verboseIter = TRUE)
# 3. Set parallel processing cluster
cl <- makePSOCKcluster(5) # create number of copies of R to run in parallel and communicate over sockets
# 3. Set parallel processing cluster
cl <- makePSOCKcluster(5) # create number of copies of R to run in parallel and communicate over sockets
registerDoParallel(cl) # register parallel backed with foreach package
# 4. Train model
nb_train <-nb_train <- train(sentiment ~ .,
data = Train,
method = "naive_bayes",
metric = "F1",
trControl = train_control,
tuneGrid = tgrid,
allowParallel= TRUE
)
knitr::opts_chunk$set(echo = TRUE)
data <- read.csv("yelp_data_small.csv",
stringsAsFactors=FALSE,
encoding = "utf-8")
library(quanteda)
library(quanteda.textstats)
library(quanteda.textplots)
corpus <- corpus(data,
text_field = "text")
prop.table(table(corpus$sentiment))
head(corpus)
toks <- tokens(corpus,
include_docvars = TRUE)
toks <- toks %>%
tokens_tolower() %>%
tokens_remove(stopwords("english"), padding = TRUE) %>%
tokens_remove('[\\p{P}\\p{S}]', valuetype = 'regex', padding = TRUE)
cols <- textstat_collocations(toks,
method = "lambda",
size = 2,
min_count = 5,
smoothing = 0.5)
cols <- cols[order(-cols$count),]
toks <- tokens_compound(toks, pattern = cols[cols$z > 10,])
toks <- tokens_remove(tokens(toks), "")
toks <- tokens(toks,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_separators = TRUE,
remove_url = TRUE)
dfm <- dfm(toks)
dfm <- dfm_trim(dfm, min_termfreq = 30)
dfm <- dfm_tfidf(dfm)
library(caret)
tmpdata <- convert(dfm, to = "data.frame", docvars = NULL)
tmpdata <- tmpdata[, -1]
sentiment <- as.factor(dfm@docvars$sentiment) # extract sentiment labels from the dfm object (hint: the dfm is an S4 class object)
ldata <- as.data.frame(cbind(sentiment, tmpdata))
train_row_nums <- createDataPartition(y = ldata$sentiment, # set sentiment as the Y variable in caret
p = 0.8, # fill in the blank
list=FALSE)
Train <- ldata[train_row_nums, ]
Test <-  ldata[-train_row_nums, ]
library('doParallel') # for parallel processing
library('naivebayes') # naive bayes classifier
library('MLmetrics') # model performance
# 1. Set grid search for NB classifier - how will you tune your parameters?
tgrid <- expand.grid(laplace = c(0,0.5,1.0),
usekernel = c(TRUE, FALSE),
adjust=c(0.75, 1, 1.25, 1.5))
# 2. Set up 5-fold cross-validation, repeated 3 times
train_control <- trainControl(method = "repeatedcv",
number = 5,
repeats = 3,
classProbs= TRUE,
summaryFunction = multiClassSummary,
selectionFunction = "best", # select the model with the best performance metric
verboseIter = TRUE)
# 3. Set parallel processing cluster
cl <- makePSOCKcluster(5) # create number of copies of R to run in parallel and communicate over sockets
registerDoParallel(cl) # register parallel backed with foreach package
# 4. Train model
nb_train <-nb_train <- train(sentiment ~ .,
data = Train,
method = "naive_bayes",
metric = "F1",
trControl = train_control,
tuneGrid = tgrid,
allowParallel= TRUE
)
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
lapply(c(),  pkgTest)
# set wd for current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load data
load(url("https://github.com/ASDS-TCD/StatsII_Spring2024/blob/main/datasets/climateSupport.RData?raw=true"))
# load data
data <- load(url("https://github.com/ASDS-TCD/StatsII_Spring2024/blob/main/datasets/climateSupport.RData?raw=true"))
View(data)
csv_data <-
?as.csv
csv_data <-
?as.csv
csv_data <-
??as.csv
csv_data <- as.data.frame(data)
View(csv_data)
as.matrix(data)
print(data)
load("C:/Users/paddy/OneDrive/Documents/GitHub/StatsII_Spring2024/datasets/climateSupport.RData")
data2 <- load("C:/Users/paddy/OneDrive/Documents/GitHub/StatsII_Spring2024/datasets/climateSupport.RData")
View(data2)
as.array(data)
print(as.array(data))
View(as.array(data))
View(as.csv(data))
View((data))
as.data.frame.vector(data)
View(as.data.frame.vector(data))
data
data$climateSupport
ls(data)
ls(data)
ls(data)
# load data
data <- load(url("https://github.com/ASDS-TCD/StatsII_Spring2024/blob/main/datasets/climateSupport.RData?raw=true"))
ls(data)
View(climateSupport)
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
lapply(c(),  pkgTest)
# set wd for current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load data
load(url("https://github.com/ASDS-TCD/StatsII_Spring2024/blob/main/datasets/climateSupport.RData?raw=true"))
View(climateSupport)
lm(choice ~ countries + sanctions, data = climateSupport)
climateSupport$choice
as.logical(climateSupport$choice)
as.logical(climateSupport$choice, "Supported" = TRUE, "Not supported" = FALSE)
as.logical(climateSupport$choice, "Supported" = TRUE, "Not supported" = FALSE)
as.integer(climateSupport$choice)
as.logical(as.integer(climateSupport$choice))
as.logical(climateSupport$choice)
ifelse(climateSupport$choice == "Supported", 1, 0)
climateSupport$choice <- ifelse(climateSupport$choice == "Supported", 1, 0)
View(climateSupport)
lm(choice ~ countries + sanctions, data = climateSupport)
glm(choice ~ countries + sanctions, data = climateSupport)
lm(choice ~ countries + sanctions, data = climateSupport)
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
lapply(c(),  pkgTest)
# set wd for current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load data
load(url("https://github.com/ASDS-TCD/StatsII_Spring2024/blob/main/datasets/climateSupport.RData?raw=true"))
lm(choice ~ countries + sanctions, data = climateSupport)
climateSupport$choice <- ifelse(climateSupport$choice == "Supported", 1, 0)
lm(choice ~ countries + sanctions, data = climateSupport)
View(climateSupport)
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
data <- read.csv("yelp_data_small.csv",
stringsAsFactors=FALSE,
encoding = "utf-8")
library(quanteda)
library(quanteda.textstats)
library(quanteda.textplots)
corpus <- corpus(data,
text_field = "text")
corpus <- corpus(data,
text_field = "text")
prop.table(table(corpus$sentiment))
prop.table(table(corpus$sentiment))
head(corpus)
toks <- tokens(corpus,
include_docvars = TRUE)
toks <- tokens(corpus,
include_docvars = TRUE)
toks <- toks %>%
tokens_tolower() %>%
tokens_remove(stopwords("english"), padding = TRUE) %>%
tokens_remove('[\\p{P}\\p{S}]', valuetype = 'regex', padding = TRUE)
cols <- textstat_collocations(toks,
method = "lambda",
size = 2,
min_count = 5,
smoothing = 0.5)
cols <- cols[order(-cols$count),]
toks <- tokens_compound(toks, pattern = cols[cols$z > 10,])
toks <- tokens_remove(tokens(toks), "")
toks <- tokens(toks,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_separators = TRUE,
remove_url = TRUE)
dfm <- dfm(toks)
dfm <- dfm_trim(dfm, min_termfreq = 30)
dfm <- dfm_trim(dfm, min_termfreq = 30)
dfm <- dfm_tfidf(dfm)
library(caret)
tmpdata <- convert(dfm, to = "data.frame", docvars = NULL)
tmpdata <- tmpdata[, -1]
sentiment <- as.factor(dfm@docvars$sentiment) # extract sentiment labels from the dfm object (hint: the dfm is an S4 class object)
ldata <- as.data.frame(cbind(sentiment, tmpdata))
train_row_nums <- createDataPartition(y = ldata$sentiment, # set sentiment as the Y variable in caret
p = 0.8, # fill in the blank
list=FALSE)
Train <- ldata[train_row_nums, ]
Test <-  ldata[-train_row_nums, ]
library('doParallel') # for parallel processing
library('naivebayes') # naive bayes classifier
library('MLmetrics') # model performance
# 1. Set grid search for NB classifier - how will you tune your parameters?
tgrid <- expand.grid(laplace = c(0,0.5,1.0),
usekernel = c(TRUE, FALSE),
adjust=c(0.75, 1, 1.25, 1.5))
# 2. Set up 5-fold cross-validation, repeated 3 times
train_control <- trainControl(method = "repeatedcv",
number = 5,
repeats = 3,
classProbs= TRUE,
summaryFunction = multiClassSummary,
selectionFunction = "best", # select the model with the best performance metric
verboseIter = TRUE)
# 3. Set parallel processing cluster
cl <- makePSOCKcluster(5) # create number of copies of R to run in parallel and communicate over sockets
# 3. Set parallel processing cluster
cl <- makePSOCKcluster(5) # create number of copies of R to run in parallel and communicate over sockets
registerDoParallel(cl) # register parallel backed with foreach package
# 4. Train model
nb_train <-nb_train <- train(sentiment ~ .,
data = Train,
method = "naive_bayes",
metric = "F1",
trControl = train_control,
tuneGrid = tgrid,
allowParallel= TRUE
)
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
lapply(c(),  pkgTest)
# set wd for current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load data
load(url("https://github.com/ASDS-TCD/StatsII_Spring2024/blob/main/datasets/climateSupport.RData?raw=true"))
View(climateSupport)
glm(formula = choice ~ countries + sanctions, family = "binomial",
data = climateSupport)
climateSupport$choice <- ifelse(climateSupport$choice == "Supported", 1, 0)
#Fitting the model using the glm function.
#Family = "binomial" tells us that the dependent variable is binary.
glm(formula = choice ~ countries + sanctions, family = "binomial",
data = climateSupport)
#Fitting the model using the glm function.
#Family = "binomial" tells us that the dependent variable is binary.
glm(formula = choice ~ countries + sanctions,
data = climateSupport)
#Fitting the model using the glm function.
#Family = "binomial" tells us that the dependent variable is binary.
glm(formula = choice ~ countries + sanctions, family = "binomial",
data = climateSupport)
knitr::opts_chunk$set(echo = TRUE)
data <- read.csv("yelp_data_small.csv",
stringsAsFactors=FALSE,
encoding = "utf-8")
data <- read.csv("yelp_data_small.csv",
stringsAsFactors=FALSE,
encoding = "utf-8")
data <- read.csv("yelp_data_small.csv",
stringsAsFactors=FALSE,
encoding = "utf-8")
library(quanteda)
library(quanteda.textstats)
library(quanteda.textplots)
corpus <- corpus(data,
text_field = "text")
corpus <- corpus(data,
text_field = "text")
prop.table(table(corpus$sentiment))
head(corpus)
toks <- tokens(corpus,
include_docvars = TRUE)
toks <- tokens(corpus,
include_docvars = TRUE)
toks <- toks %>%
tokens_tolower() %>%
tokens_remove(stopwords("english"), padding = TRUE) %>%
tokens_remove('[\\p{P}\\p{S}]', valuetype = 'regex', padding = TRUE)
cols <- textstat_collocations(toks,
method = "lambda",
size = 2,
min_count = 5,
smoothing = 0.5)
cols <- cols[order(-cols$count),]
toks <- tokens_compound(toks, pattern = cols[cols$z > 10,])
toks <- tokens_remove(tokens(toks), "")
toks <- tokens(toks,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_separators = TRUE,
remove_url = TRUE)
dfm <- dfm(toks)
dfm <- dfm_trim(dfm, min_termfreq = 30)
dfm <- dfm_trim(dfm, min_termfreq = 30)
dfm <- dfm_tfidf(dfm)
library(caret)
tmpdata <- convert(dfm, to = "data.frame", docvars = NULL)
tmpdata <- convert(dfm, to = "data.frame", docvars = NULL)
tmpdata <- tmpdata[, -1]
sentiment <- as.factor(dfm@docvars$sentiment) # extract sentiment labels from the dfm object (hint: the dfm is an S4 class object)
ldata <- as.data.frame(cbind(sentiment, tmpdata))
train_row_nums <- createDataPartition(y = ldata$sentiment, # set sentiment as the Y variable in caret
p = 0.8, # fill in the blank
list=FALSE)
Train <- ldata[train_row_nums, ]
Train <- ldata[train_row_nums, ]
Test <-  ldata[-train_row_nums, ]
library('doParallel') # for parallel processing
library('naivebayes') # naive bayes classifier
library('MLmetrics') # model performance
# 1. Set grid search for NB classifier - how will you tune your parameters?
tgrid <- expand.grid(laplace = c(0,0.5,1.0),
usekernel = c(TRUE, FALSE),
adjust=c(0.75, 1, 1.25, 1.5))
# 2. Set up 5-fold cross-validation, repeated 3 times
train_control <- trainControl(method = "repeatedcv",
number = 5,
repeats = 3,
classProbs= TRUE,
summaryFunction = multiClassSummary,
selectionFunction = "best", # select the model with the best performance metric
verboseIter = TRUE)
# 3. Set parallel processing cluster
cl <- makePSOCKcluster(5) # create number of copies of R to run in parallel and communicate over sockets
# 3. Set parallel processing cluster
cl <- makePSOCKcluster(5) # create number of copies of R to run in parallel and communicate over sockets
registerDoParallel(cl) # register parallel backed with foreach package
